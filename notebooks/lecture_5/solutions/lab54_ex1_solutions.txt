###### EXERCISE 1 SOLUTION ######
prompt = "The future of AI is"
temperatures = [0.1, 1.0, 2.0]
generated_texts = []

for temp in temperatures:
    input_ids = tokenizer.encode(prompt, return_tensors='pt')
    attention_mask = torch.ones_like(input_ids)
    output = model.generate(
        input_ids,
        max_length=50,
        temperature=temp,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,  # Set pad token ID to EOS token ID
        attention_mask=attention_mask  # Provide attention mask
    )
    generated_texts.append(tokenizer.decode(output[0], skip_special_tokens=True))

for text in generated_texts:
    loss, perplexity = calculate_perplexity(model, tokenizer, text)
    print(f"Generated Text: {text}\nLoss: {loss:.4f}, Perplexity: {perplexity:.4f}\n")
    print('-'*30)
###### END OF SOLUTION ######