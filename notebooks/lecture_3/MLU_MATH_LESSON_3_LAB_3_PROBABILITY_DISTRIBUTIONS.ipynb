{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<div style=\"background-image: linear-gradient(145deg, rgba(35, 47, 62, 1) 0%, rgba(0, 49, 129, 1) 40%, rgba(32, 116, 213, 1) 60%, rgba(244, 110, 197, 1) 85%, rgba(255, 173, 151, 1) 100%); padding: 1rem 2rem; width: 95%\"><img style=\"width: 60%;\" src=\"../../images/MLU_logo.png\"></div>\n",
    "\n",
    "# <a name=\"0\">MLU Mathematical Fundamentals for Machine Learning</a>\n",
    "# <a name=\"0\">Lecture 3: Probability and Statistics Fundamentals</a>\n",
    "## <a name=\"0\">Lab 3.3: Probability Distributions</a>\n",
    "\n",
    " 1. <a href=\"#1\">Discrete Distributions</a> \n",
    " 2. <a href=\"#2\">Continuous Distributions</a> \n",
    " \n",
    "This notebook covers some important discrete and continuous statistical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## <a name=\"1\">1. Discrete Distributions</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now that we have learned how to work with probability in both the discrete and the continuous setting, let us get to know some of the common distributions encountered. Depending on the area of machine learning, we may need to be familiar with vastly more of these, or for some areas of deep learning potentially none at all. This is, however, a good basic list to be familiar with.\n",
    "\n",
    "## Bernoulli\n",
    "\n",
    "This is the simplest random variable usually encountered.  This random variable encodes a coin flip which comes up $1$ with probability $p$ and $0$ with probability $1-p$.  If we have a random variable $X$ with this distribution, we will write\n",
    "\n",
    "$$\n",
    "X \\sim \\mathrm{Bernoulli}(p).\n",
    "$$\n",
    "\n",
    "The cumulative distribution function is \n",
    "\n",
    "$$F(x) = \\begin{cases} 0 & x < 0, \\\\ 1-p & 0 \\le x < 1, \\\\ 1 & x >= 1 . \\end{cases}$$\n",
    "\n",
    "The probability mass function is plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.stem([0, 1], [1 - p, p])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p.m.f.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "If $X \\sim \\mathrm{Bernoulli}(p)$, then:\n",
    "\n",
    "* $\\mu_X = p$,\n",
    "* $\\sigma_X^2 = p(1-p)$.\n",
    "\n",
    "We can sample an array of arbitrary shape from a Bernoulli random variable as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "1 * (np.random.rand(10, 10) < p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Discrete Uniform\n",
    "\n",
    "The next commonly encountered random variable is a discrete uniform.  For our discussion here, we will assume that it is supported on the integers $\\{1, 2, \\ldots, n\\}$, however any other set of values can be freely chosen.  The meaning of the word *uniform* in this context is that every possible value is equally likely.  The probability for each value $i \\in \\{1, 2, 3, \\ldots, n\\}$ is $p_i = \\displaystyle{\\frac{1}{n}}$.  We will denote a random variable $X$ with this distribution as\n",
    "\n",
    "$$\n",
    "X \\sim U(n).\n",
    "$$\n",
    "\n",
    "The cumulative distribution function is \n",
    "\n",
    "$$F(x) = \\begin{cases} 0 & x < 1, \\\\ \\displaystyle{\\frac{k}{n}} & k \\le x < k+1 \\text{ with } 1 \\le k < n, \\\\ 1 & x >= n . \\end{cases}$$\n",
    "\n",
    "Let us first plot the probability mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.stem([i + 1 for i in range(n)], n * [1 / n])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p.m.f.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "If $X \\sim U(n)$, then:\n",
    "\n",
    "* $\\mu_X = \\displaystyle{\\frac{1+n}{2}}$,\n",
    "* $\\sigma_X^2 = \\displaystyle{\\frac{n^2-1}{12}}$.\n",
    "\n",
    "We can sample an array of arbitrary shape from a discrete uniform random variable as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.randint(1, n, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Binomial\n",
    "\n",
    "Let us make things a little more complex and examine the *binomial* random variable.  This random variable originates from performing a sequence of $n$ independent experiments, each of which has probability $p$ of succeeding, and asking how many successes we expect to see.\n",
    "\n",
    "Let us express this mathematically.  Each experiment is an independent random variable $X_i$ where we will use $1$ to encode success, and $0$ to encode failure.  Since each is an independent coin flip which is successful with probability $p$, we can say that $X_i \\sim \\mathrm{Bernoulli}(p)$.  Then, the binomial random variable is\n",
    "\n",
    "$$\n",
    "X = \\sum_{i=1}^n X_i.\n",
    "$$\n",
    "\n",
    "In this case, we will write\n",
    "\n",
    "$$\n",
    "X \\sim \\mathrm{Binomial}(n, p).\n",
    "$$\n",
    "\n",
    "To get the cumulative distribution function, we need to notice that getting exactly $k$ successes can occur in $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ ways each of which has a probability of $p^k(1-p)^{n-k}$ of occurring.  Thus the cumulative distribution function is\n",
    "\n",
    "$$F(x) = \\begin{cases} 0 & x < 0, \\\\ \\displaystyle{\\sum_{m \\le k} \\binom{n}{m} p^m(1-p)^{n-m}}  & k \\le x < k+1 \\text{ with } 0 \\le k < n, \\\\ 1 & x >= n . \\end{cases}$$\n",
    "\n",
    "Let us first plot the probability mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n, p = 10, 0.2\n",
    "\n",
    "# Compute binomial coefficient\n",
    "def binom(n, k):\n",
    "    comb = 1\n",
    "    for i in range(min(k, n - k)):\n",
    "        comb = comb * (n - i) // (i + 1)\n",
    "    return comb\n",
    "\n",
    "\n",
    "pmf = np.array([p ** i * (1 - p) ** (n - i) * binom(n, i) for i in range(n + 1)])\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.stem([i for i in range(n + 1)], pmf)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p.m.f.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "tags": []
   },
   "source": [
    "While this result is not simple, the means and variances are.  If $X \\sim \\mathrm{Binomial}(n, p)$, then:\n",
    "\n",
    "* $\\mu_X = np$,\n",
    "* $\\sigma_X^2 = np(1-p)$.\n",
    "\n",
    "This can be sampled as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.binomial(n, p, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## <a name=\"2\">2. Continuous Distributions</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "## Continuous Uniform\n",
    "\n",
    "Next, let us discuss the continuous uniform distribution. The idea behind this random variable is that if we increase the $n$ in the discrete uniform distribution, and then scale it to fit within the interval $[a, b]$, we will approach a continuous random variable that just picks an arbitrary value in $[a, b]$ all with equal probability.  We will denote this distribution as\n",
    "\n",
    "$$\n",
    "X \\sim U(a, b).\n",
    "$$\n",
    "\n",
    "The probability density function is \n",
    "\n",
    "$$p(x) = \\begin{cases} \\displaystyle{\\frac{1}{b-a}} & x \\in [a, b], \\\\ 0 & x \\not\\in [a, b].\\end{cases}$$\n",
    "\n",
    "The cumulative distribution function is \n",
    "\n",
    "$$F(x) = \\begin{cases} 0 & x < a, \\\\ \\displaystyle{\\frac{x-a}{b-a}} & x \\in [a, b], \\\\ 1 & x >= b . \\end{cases}$$\n",
    "\n",
    "Let us first plot the probability density function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a, b = 1, 3\n",
    "\n",
    "x = np.arange(0, 4, 0.01)\n",
    "p = (x > a) * (x < b) / (b - a)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(x, p)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p.d.f.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "If $X \\sim U(a, b)$, then:\n",
    "\n",
    "* $\\mu_X = \\displaystyle{\\frac{a+b}{2}}$,\n",
    "* $\\sigma_X^2 = \\displaystyle{\\frac{(b-a)^2}{12}}$.\n",
    "\n",
    "We can sample an array of arbitrary shape from a uniform random variable as follows.  Note that it by default samples from a $U(0,1)$, so if we want a different range we need to scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(b - a) * np.random.rand(10, 10) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Gaussian or Normal\n",
    "\n",
    "We say a random variable $X$ is normally distributed with given mean $\\mu$ and variance $\\sigma^2$, written $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ if $X$ has density\n",
    "\n",
    "$$p_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\displaystyle{\\frac{(x-\\mu)^2}{2\\sigma^2}}}.$$\n",
    "\n",
    "Let us first plot the probability density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, sigma = 0, 1\n",
    "\n",
    "x = np.arange(-3, 3, 0.01)\n",
    "p = 1 / np.sqrt(2 * np.pi * sigma ** 2) * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(x, p)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p.d.f.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The Gaussian is what is known as a *maximum entropy distribution*.  We will get into entropy more deeply in the Information Theory section of lecture 5, however all we need to know at this point is that it is a measure of randomness.  In a rigorous mathematical sense, we can think of the Gaussian as the *most* random choice of random variable with fixed mean and variance.  Thus, if we know that our random variable has some mean and variance, the Gaussian is in a sense the most conservative choice of distribution we can make.\n",
    "\n",
    "To close the section, Let us recall that if $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then:\n",
    "\n",
    "* $\\mu_X = \\mu$,\n",
    "* $\\sigma_X^2 = \\sigma^2$.\n",
    "\n",
    "We can sample from the Gaussian (or standard normal) distribution as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.normal(mu, sigma, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<div style=\"align: left; border: 4px solid cornflowerblue; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px; width: 65%\">\n",
    "        <img style=\"float: left; max-width: 80%; max-height:80%; margin: 5px;\" src=\"../../images/MLU_challenge.png\" alt=\"MLU challenge\" width=12% height=12%/>\n",
    "    <span style=\"padding: 20px; align: left;\">\n",
    "        <p><b>Try it yourself!</b></p>\n",
    "        <p><b>Exercise 1.</b>Look at the <code>scipy</code> python package documentation and find the function to generate the standard normal PDF (Probability Density Function) and plot it. Make sure to include the necessary imports.</p>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### YOUR CODE HERE ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### END OF CODE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/lab33_ex1_solutions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "<div style=\"align: left; border: 4px solid cornflowerblue; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px; width: 65%\">\n",
    "        <img style=\"float: left; max-width: 80%; max-height:80%; margin: 5px;\" src=\"../../images/MLU_challenge.png\" alt=\"MLU challenge\" width=12% height=12%/>\n",
    "    <span style=\"padding: 20px; align: left;\">\n",
    "        <p><b>Try it yourself!</b></p>\n",
    "        <p><b>Exercise 2.</b>Look at the <code>scipy</code> python package documentation and find the function to generate the standard normal CDF (Cumulative Density Function) and plot it. You should have already imported the necessary library in Exercise 1.</p>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### YOUR CODE HERE ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### END OF CODE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/lab33_ex2_solutions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<div style=\"align: left; border: 4px solid cornflowerblue; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px; width: 65%\">\n",
    "        <img style=\"float: left; max-width: 80%; max-height:80%; margin: 5px;\" src=\"../../images/MLU_challenge.png\" alt=\"MLU challenge\" width=12% height=12%/>\n",
    "    <span style=\"padding: 20px; align: left;\">\n",
    "        <p><b>Try it yourself!</b></p>\n",
    "        <p><b>Exercise 3.</b>Look at the <code>scipy</code> python package documentation and find the function to generate a 10 by 10 array random sample from the standard normal distribution and print it. You should have already imported the necessary library in Exercise 1.</p>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### YOUR CODE HERE ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### END OF CODE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/lab33_ex3_solutions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "In these three excercises we have seen how straightforward the <code>scipy</code> library it is to use to generate theoretical probability distributions given their parameters as well as to generate random samples drawn from a given distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Final Project Note\n",
    "<img src=\"../../images/MLU_question.png\" width=80 height=80 />\n",
    "\n",
    "Predicting human behaviour is impossible  - there is randomness in the data generation, data collection, matrix decomposition choices, there is also noise layered on top of the ground truth noise. For instance, if you asked a person to rate a book on 100 different random days, they might not always give the same rating - perhaps personal concerns would nudge the score up or down by a star.  How to encode the variablity of the data and of the process into the model? Gaussian noise is one way to account for and incorporate noise into machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: left; background-color:#330066; width:99%;\"> \n",
    "        <img style=\"float: left; max-width: 100%; max-height:100%; margin: 15px;\" src=\"../../images/MLU_robot.png\" alt=\"MLU robot\" width=\"100\" height=\"100\"/>\n",
    "    <span style=\"color: white; padding-left: 10px; align: left; margin: 15px;\">\n",
    "        <h3>Congratulations!</h3>\n",
    "        You have completed Lab 3.3: Probability Distributions of Lecture 3: Probability and Statistics Fundamentals of MLU Mathematical Fundamentals of Machine Learning.\n",
    "        <br/>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
