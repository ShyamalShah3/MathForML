{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<div style=\"background-image: linear-gradient(145deg, rgba(35, 47, 62, 1) 0%, rgba(0, 49, 129, 1) 40%, rgba(32, 116, 213, 1) 60%, rgba(244, 110, 197, 1) 85%, rgba(255, 173, 151, 1) 100%); padding: 1rem 2rem; width: 95%\"><img style=\"width: 60%;\" src=\"../../images/MLU_logo.png\"></div>\n",
    "\n",
    "# <a name=\"0\">MLU Mathematical Fundamentals for Machine Learning</a>\n",
    "# <a name=\"0\">Lecture 3: Probability and Statistics Fundamentals</a>\n",
    "## <a name=\"0\">Lab 3.4: Inferential Statistics and the Central Limit Theorem</a>\n",
    "\n",
    " 1. <a href=\"#1\">Central Limit Theorem</a> \n",
    " 2. <a href=\"#2\">Confidence Interval for the Mean</a> \n",
    " \n",
    "This notebook empirically shows how the Central Limit Theorem works by using random samples from three different distributions: continuous uniform, exponential and binomial.\n",
    "It also describes how to construct a confidence interval for the mean of a population using the Normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## <a name=\"1\">1. Central Limit Theorem</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "The **Central Limit Theorem (CLT)** states that, given a large enough sample size $n$, drawn from a population with mean $\\mu$ and standard deviation $\\sigma$, the sampling distribution of the sample mean is normally distributed with mean $\\mu$ and standard deviation $\\sigma$ divided by the square root of $n$.\n",
    "\n",
    "$$ \\bar{X}=\\frac{1}{n} \\sum_{i=1}^n x_i$$ \n",
    "\n",
    "$$ \\bar{X} \\sim N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$$ \n",
    "\n",
    "This is a very powerful theorem because it allows us to approximate the sample mean of a sample drawn from any population to a normal distribution and therefore use all the tools we already know to compute probabilities of intervals on normal distributions. \n",
    "\n",
    "In order to leverage the PDF and CDF of the **Standard Normal**, we will standardise the sample mean by subtracting its mean and dividing by its variance.\n",
    "\n",
    "$$ \\frac{\\bar{X}-\\mu}{\\displaystyle{\\frac{\\sigma}{\\sqrt{n}}}} \\sim N(0,1)$$ \n",
    "\n",
    "We will now see how the CLT really works in practice with different probability distributions to sample from and different sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform, binom, expon, norm, bernoulli\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Let's start sampling from a *Uniform* population $Uniform[0,1]$. \n",
    "\n",
    "\n",
    "<img style=\"width: 40%;\" src=\"../../images/clt.png\"></div>\n",
    "\n",
    "We will take $m$ samples and each sample will have size $n$. We will fix $m=1200$ and start with a sample size of each sample $n=50$.\n",
    "\n",
    "We'll end up with a sample of sample means which we standardise and then we can plot the histogram (in blue) and compare it with the standard normal PDF (red line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform[0, 1]\n",
    "mu = uniform.mean(loc=0, scale=1)\n",
    "sigma = uniform.std(loc=0, scale=1)\n",
    "\n",
    "n = 50 # sample size\n",
    "m = 1200 # number of samples\n",
    "\n",
    "print(f\"Taking {m} samples each of size {n} from a Uniform[0,1] with mean {mu} and standard deviation {sigma}\")\n",
    "\n",
    "x = np.zeros([m, n])\n",
    "standardised_sample_mean = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    x[i] = uniform.rvs(loc=0, scale=1, size=n, random_state=None)\n",
    "    sample_mean = (x[i].sum()) / n\n",
    "    standard_error = sigma / np.sqrt(n)\n",
    "    standardised_sample_mean[i] = (sample_mean - mu) / standard_error\n",
    "    \n",
    "plt.hist(standardised_sample_mean, bins=40, density=True)\n",
    "plt.plot(np.arange(-4, 4, 8/m), norm.pdf(np.arange(-4, 4, 8/m), loc=0, scale=1), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Despite the uniform distribution is quite different from the Normal, we can see that its sample mean for a sample size $n=50$ is approximately normal. Pretty powerful, don't you think?\n",
    "\n",
    "Let's see now how the normal approximation changes for $4$ different values of the sample size $n \\in {1, 10, 100, 1000}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform[0, 1]\n",
    "mu = uniform.mean(loc=0, scale=1)\n",
    "sigma = uniform.std(loc=0, scale=1)\n",
    "\n",
    "n_values = [1, 10, 100, 1000] # sample size\n",
    "m = 1200 # number of samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for j in range(len(n_values)):\n",
    "    n = n_values[j]\n",
    "    plt.subplot(2, 2, j + 1)\n",
    "    x = np.zeros([m, n])\n",
    "    standardised_sample_mean = np.zeros(m)\n",
    "\n",
    "    for i in range(m):\n",
    "        x[i] = uniform.rvs(loc=0, scale=1, size=n, random_state=None)\n",
    "        sample_mean = (x[i].sum()) / n\n",
    "        standard_error = sigma / np.sqrt(n)\n",
    "        standardised_sample_mean[i] = (sample_mean - mu) / standard_error\n",
    "    \n",
    "    plt.hist(standardised_sample_mean, bins=40, density=True)\n",
    "    plt.plot(np.arange(-4, 4, 8/m), norm.pdf(np.arange(-4, 4, 8/m), loc=0, scale=1), color='r')\n",
    "    plt.title(f\"sample size $n$: {n}\")\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.8)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Let's now do the same while sampling from an *Exponential* population with parameter $\\lambda=1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential lambda=1\n",
    "mu = expon.mean(loc=0, scale=1)\n",
    "sigma = expon.std(loc=0, scale=1)\n",
    "\n",
    "n_values = [1, 10, 100, 1000] # sample size\n",
    "m = 1200 # number of samples\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for j in range(len(n_values)):\n",
    "    n = n_values[j]\n",
    "    plt.subplot(2, 2, j + 1)\n",
    "    x = np.zeros([m, n])\n",
    "    standardised_sample_mean = np.zeros(m)\n",
    "\n",
    "    for i in range(m):\n",
    "        x[i] = expon.rvs(loc=0, scale=1, size=n, random_state=None)\n",
    "        sample_mean = (x[i].sum()) / n\n",
    "        standard_error = sigma / np.sqrt(n)\n",
    "        standardised_sample_mean[i] = (sample_mean - mu) / standard_error\n",
    "    \n",
    "    plt.hist(standardised_sample_mean, bins=40, density=True)\n",
    "    plt.plot(np.arange(-4, 4, 8/m), norm.pdf(np.arange(-4, 4, 8/m), loc=0, scale=1), color='r')\n",
    "    plt.title(f\"sample size $n$: {n}\")\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.8)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can see that the exponential PDF is not symmetrical with respect to the mean and therefore we need to increase the sample size $n$ to about $100$ to achieve symmetry in the distribution of its sample mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<div style=\"align: left; border: 4px solid cornflowerblue; text-align: left; margin: auto; padding-left: 20px; padding-right: 20px; width: 65%\">\n",
    "        <img style=\"float: left; max-width: 80%; max-height:80%; margin: 5px;\" src=\"../../images/MLU_challenge.png\" alt=\"MLU challenge\" width=12% height=12%/>\n",
    "    <span style=\"padding: 20px; align: left;\">\n",
    "        <p><b>Try it yourself!</b></p>\n",
    "        <p><b>Exercise 1.</b>Try generating the same data and plots above for a random sample drawn from a binomial distribution with parameters n=20 and p=0.5.</p>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### YOUR CODE HERE ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### END OF CODE ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/lab34_ex1_solutions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## <a name=\"2\">2. Confidence Interval for the Mean</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "If weâ€™re working with larger samples ($n \\geq 30$), we can assume that the sampling distribution of the sample mean is normally distributed (thanks to the Central Limit Theorem) and can use the <code>norm.interval()</code> function from the <code>scipy.stats</code> library to compute the lower bound and the upper bound of the confidence interval for the true mean.\n",
    "\n",
    "The following example shows how to calculate a confidence interval for the true population mean of a Bernoulli distribution using a sample of size $100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sample data\n",
    "sample_size = 100\n",
    "\n",
    "data = bernoulli.rvs(p=0.5, size=sample_size)\n",
    "\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 95% confidence interval for population mean weight\n",
    "lower_bound, upper_bound = norm.interval(confidence=0.95, loc=np.mean(data), scale=np.std(data)/np.sqrt(sample_size))\n",
    "\n",
    "print(f\"The true mean of the population lies between {lower_bound} and {upper_bound} with 95% confidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "The sample was drawn from a population with mean $p=0.5$ and we can see the confidence interval includes this value. This was just a very short example on confidence intervals, more on this topic will be explored at the beginning of Lecture 5 with Hypotheis Testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: left; background-color:#330066; width:99%;\"> \n",
    "        <img style=\"float: left; max-width: 100%; max-height:100%; margin: 15px;\" src=\"../../images/MLU_robot.png\" alt=\"MLU robot\" width=\"100\" height=\"100\"/>\n",
    "    <span style=\"color: white; padding-left: 10px; align: left; margin: 15px;\">\n",
    "        <h3>Congratulations!</h3>\n",
    "        You have completed Lab 3.4: Inferential Statistics and the Central Limit Theorem of Lecture 3: Probability and Statistics Fundamentals of MLU Mathematical Fundamentals of Machine Learning.\n",
    "        <br/>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
